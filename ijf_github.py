# -*- coding: utf-8 -*-
"""IJF - github

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/146HIVqKqcPf35BmHaAsFBbCoW5puzUch
"""



import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import copy, math

import miceforest as mf

def get_data(power,prediction,context):
    data_length = power.shape[0]
    prediction_length = prediction
    context_length = context

    train_length = data_length

    train_samples = (train_length - prediction_length - context_length)

    xtr_list = []
    ytr_list = []

    for i in range(train_samples):
        xtr_list.append(power[i:context_length+prediction_length+i].reshape((1,-1)))
        
    x = np.vstack(xtr_list)
    
    return x

def fill_ndarray(t1):
    for i in range(t1.shape[1]):  
        temp_col = t1[:, i]  
        nan_num = np.count_nonzero(temp_col != temp_col)
        if nan_num != 0:  
            temp_not_nan_col = temp_col[temp_col == temp_col]  
            temp_col[np.isnan(temp_col)] = temp_not_nan_col.mean()  
    return t1

power = pd.read_csv('Capacity factors 2007-2013.csv',delimiter=',')['4456'].values
power = fill_ndarray(power.reshape((-1,1)))

context_length = 6
prediction_length = 1

xfull = get_data(power,prediction=prediction_length,context=context_length)
K = prediction_length

def pinball_loss(observation,pred,alpha):
    error = observation - pred
    loss = np.mean(np.maximum(error*alpha,(alpha-1)*error))
    return loss

### Choose a missing pattern
#### Simulate Curtailment #######

xmiss = np.copy(power)
xmiss_flat = xmiss.flatten()

xmiss_flat[np.where(xmiss_flat > 0.87)] = np.nan
xmiss = get_data(xmiss_flat,prediction=prediction_length,context=context_length)


mask = np.isfinite(xmiss) # binary mask that indicates which values are missing

index = math.floor(xmiss.shape[0]*0.8)
x_train = xmiss[:index,:]
x_test = xmiss[index:,:]

x_test_na = np.copy(x_test)
x_test_na[:,-K:] = np.nan

x_real = xfull[index:,:]
x_test_real = x_real[:,-K:]

##### Sporadic Missingness ######
'''
np.random.seed(1234)
n = power.shape[0] # number of observations
p = power.shape[1] # number of features

perc_miss = 0.2 # 20% of missing data
xmiss = np.copy(power)
xmiss_flat = xmiss.flatten()
miss_pattern = np.random.choice(n*p, int(np.floor(n*p*perc_miss)), replace=False)
xmiss_flat[miss_pattern] = np.nan 
xmiss = get_data(xmiss_flat,prediction=prediction_length,context=context_length)

mask = np.isfinite(xmiss) # binary mask that indicates which values are missing

index = math.floor(xmiss.shape[0]*0.8)
x_train = xmiss[:index,:]
x_test = xmiss[index:,:]

x_test_na = np.copy(x_test)
x_test_na[:,-K:] = np.nan

x_real = xfull[index:,:]
x_test_real = x_real[:,-K:]
'''

####### Block Missingness #########
'''
np.random.seed(1234)
n = power.shape[0] # number of observations
p = power.shape[1] # number of features

perc_miss = 0.01 # 50% of missing data
xmiss = np.copy(power)
xmiss_flat = xmiss.flatten()
index_pre = np.random.choice(n*p, int(np.floor(n*p*perc_miss)), replace=False)
length = np.random.randint(5, 30, size=int(np.floor(n*p*perc_miss)))
index_pro = []
for i in range(int(np.floor(n*p*0.01))):
  index_pro.append(index_pre[i]+np.array([j for j in range(length[i])]))
index_pro = np.concatenate(index_pro)

index_pro = np.unique(index_pro)

xmiss_flat[index_pro] = np.nan 
xmiss = get_data(xmiss_flat,prediction=prediction_length,context=context_length)

mask = np.isfinite(xmiss) # binary mask that indicates which values are missing

index = math.floor(xmiss.shape[0]*0.8)
x_train = xmiss[:index,:]
x_test = xmiss[index:,:]

x_test_na = np.copy(x_test)
x_test_na[:,-K:] = np.nan

x_real = xfull[index:,:]
x_test_real = x_real[:,-K:]
'''

m_index = np.where(np.isnan(x_test[:,-K:])==False)

#K step
score = []
n = 100

for k in range(K):
  index = [i for i in range(context_length)]+[context_length+k]
  df = pd.DataFrame(x_train[:,index])
  kernel = mf.MultipleImputedKernel(df,datasets=n,save_all_iterations=True,random_state=1)


  kernel.mice(10,verbose=True)
  df_test = pd.DataFrame(x_test_na[:,index])

  test_data_imputed = kernel.impute_new_data(new_data=df_test)
  pred_mi = []
  for i in range(n):
    pred_mi.append(test_data_imputed.complete_data(i).values)
  pred_mi = np.array(pred_mi)
  pred_mi_mean = np.mean(pred_mi,axis=0)[:,-1]

  fcs_index = np.where(np.isnan(x_test[:,context_length+k])==False)
  print('mse:', np.mean(np.power(pred_mi_mean-x_test_real[:,k],2)[fcs_index]))
  score.append(np.mean(np.power(pred_mi_mean-x_test_real[:,k],2)[fcs_index]))

  alphas = [i/100 for i in range(1,100,1)]
  loss = []

  for alpha in alphas:
    quantile = np.quantile(pred_mi,alpha,axis=0)[:,-1]
    loss.append(pinball_loss(x_test_real[:,k][fcs_index],quantile[fcs_index],alpha))
  print('crps:', np.average(loss)*2)